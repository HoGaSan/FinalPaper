---
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: true
---

\graphicspath{ {Input/} }


### Model Assessment

#### Initial model

The initial model (using almost only default settings) provided the following performance metrics:

##### Reported on training data.

The model performance metrics are the following on the train data set.

| Metric name           | Metric value          |
|:----------------------|:----------------------|
|MSE|0.005354946|
|RMSE|0.0731775|
|LogLoss|0.0278349|
|Mean Per-Class Error|0.4181091|
|AUC|0.8833093|
|Gini|0.7666185|


Confusion Matrix

|     | 0      | 1      | Error  |
|:----|:-------|:-------|:-------|
|0|9215132|109455|0.011738|
|1|42713|9093|0.824480|
|Totals|9257845|118548|0.016229|


\begin{centering}

Receiver Operating Characteristic (ROC) curve

\includegraphics[width=100mm]{GBM_InitModel_ROC_train}

\end{centering}

##### Reported on validation data.

The model performance metrics are the following on the validation data set.

| Metric name           | Metric value          |
|:----------------------|:----------------------|
|MSE|0.005418781|
|RMSE|0.07361237|
|LogLoss|0.02848955|
|Mean Per-Class Error|0.4132652|
|AUC|0.8726363|
|Gini|0.7452726|


Confusion Matrix

|     | 0      | 1      | Error  |
|:----|:-------|:-------|:-------|
|0|3059226|48186|0.015507|
|1|14111|3288|0.811024|
|Totals|3073337|51474|0.019936|

\begin{centering}

Receiver Operating Characteristic (ROC) curve

\includegraphics[width=100mm]{GBM_InitModel_ROC_valid}

\end{centering}

##### Variable Importances

The ten most importance predictor variables are the following:

|   |Variable|Relative|Scaled  |Percentage |
|:--|-------:|-------:|-------:|----------:|
|1|FlightDate|1700.398682|1.000000|0.340196|
|2|Dest|1072.529175|0.630752|0.214579|
|3|UniqueCarrier|662.508667|0.389620|0.132547|
|4|Origin|558.006104|0.328162|0.111639|
|5|Month|521.196716|0.306514|0.104275|
|6|ArrTimeBlk|282.533051|0.166157|0.056526|
|7|Quarter|122.561745|0.072078|0.024521|
|8|DepTimeBlk|66.628983|0.039184|0.013330|
|9|CRSElapsedTime|4.880882|0.002870|0.000977|
|10|Year|3.061660|0.001801|0.000613|


\begin{centering}

\includegraphics[width=120mm]{GBM_InitModel_variable_importance}

\end{centering}

##### Assessment

The performance of the model seemed to be excellent (AUCs of 0.8833 and 0.8726 with less than 2% incorrect hits) until I checked the variable importance and the false negative predictions.

The fact that the flight date got a very high relative importance and that the year predictor is in the top 10 as well, shows that for a future data set this model can't be used and the final model should not use these predictors.

The false negative hits in the model shows that even with the boosted (and reduced) data set the needle in the haystack effect is still present and in a real world scenario this model would not be very useful.


#### Final model

The final model using carefully selected model parameters provided the following performance metrics:

##### Reported on training data.

The model performance metrics are the following on the train data set.

| Metric name           | Metric value          |
|:----------------------|:----------------------|
|MSE|0.005349638|
|RMSE|0.07314122|
|LogLoss|0.02917852|
|Mean Per-Class Error|0.4221072|
|AUC|0.8570096|
|Gini|0.7140191|


Confusion Matrix

|     | 0      | 1      | Error  |
|:----|:-------|:-------|:-------|
|0|9268544|56043|0.006010|
|1|43424|8382|0.838204|
|Totals|9311968|64425|0.010608|


\begin{centering}

Receiver Operating Characteristic (ROC) curve

\includegraphics[width=100mm]{GBM_Model_ROC_train}

\end{centering}

##### Reported on validation data.

The model performance metrics are the following on the validation data set.

| Metric name           | Metric value          |
|:----------------------|:----------------------|
|MSE|0.005611805|
|RMSE|0.07491198|
|LogLoss|0.03130175|
|Mean Per-Class Error|0.4426331|
|AUC|0.8215208|
|Gini|0.6430415|


Confusion Matrix

|     | 0      | 1      | Error  |
|:----|:-------|:-------|:-------|
|0|3082632|24780|0.007974|
|1|15264|2135|0.877292|
|Totals|3097896|26915|0.012815|


\begin{centering}

Receiver Operating Characteristic (ROC) curve

\includegraphics[width=100mm]{GBM_Model_ROC_train}

\end{centering}


##### Variable Importances

The ten most importance predictor variables are the following:

|   |Variable|Relative|Scaled  |Percentage |
|:--|-------:|-------:|-------:|----------:|
|1|Origin|1068.777588|1.000000|0.225305|
|2|Dest|873.531250|0.817318|0.184146|
|3|ArrTimeBlk|673.985229|0.630613|0.142080|
|4|Month|523.576965|0.489884|0.110373|
|5|DepTimeBlk|515.629517|0.482448|0.108698|
|6|UniqueCarrier|337.862000|0.316120|0.071223|
|7|DayofMonth|254.428879|0.238056|0.053635|
|8|FlightNum|143.676224|0.134430|0.030288|
|9|DayOfWeek|120.171158|0.112438|0.025333|
|10|DistanceGroup|78.397850|0.073353|0.016527|

\begin{centering}

\includegraphics[width=120mm]{GBM_Model_variable_importance}

\end{centering}

##### Scoring

The scoring was done using the 20% of the records from data set separated at the beginning of the model building. The confusion matrix is the following:

|     | 0      | 1      | Error  |
|:----|:-------|:-------|:-------|
|0|3082474|25926|0.008341|
|1|14791|2224|0.869292|
|Totals|3097265|28150|0.013028|

##### Assessment

While the changes in the model parameters and predictors made the model more useful from the business domain point of view, the performance of the model did not drop significantly (AUCs changed from 0.8833 to 0.8570 and from 0.8726 to 0.8215 with less than 1.3% incorrect hits). Unfortunately the same can be said about the false negative hits as well, which got even worst and still shows the needle in the haystack effect, making the model unrealistic for a real world scenario.

The scoring provided almost the same performance, what I got for the validation data assessment, confirming that the use of the model would not be beneficial in a real world scenario.

### Revised Parameter Settings

I've did two main changes regarding the model parameters. The first major change was to remove those predictors, which were not useful for future runs, while the second major change was to increase the number of trees to be build from 50 to 200 while training the model and let the model building algorithm stop whenever more trees do not increase the model performance significantly.
